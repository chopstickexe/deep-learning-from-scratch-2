{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch07-seq2seq.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNTRRIWgRrEkU8XBypCjFzT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chopstickexe/deep-learning-from-scratch-2/blob/master/ch07_seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMKwPjfsSDLh",
        "colab_type": "text"
      },
      "source": [
        "# 下準備\n",
        "\n",
        "$$\n",
        "\\newcommand{\\vect}[1]{\\mathbf{#1}}\n",
        "\\newcommand{\\mat}[1]{\\mathbf{#1}}\n",
        "$$\n",
        "\n",
        "## 数式の表記\n",
        "\n",
        "変数: 小文字イタリック $x$\n",
        "\n",
        "定数: 大文字イタリック $X$\n",
        "\n",
        "ベクトル: 小文字ローマン体太字 $\\vect{x}$\n",
        "\n",
        "行列: 大文字ローマン体太字 $\\mat{X}$\n",
        "\n",
        "## 公式実装のclone"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpcQLFeCSHyH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a64cfdfa-08d9-4d4a-8a20-25302ef1f41a"
      },
      "source": [
        "!git clone --depth=1 https://github.com/oreilly-japan/deep-learning-from-scratch-2.git\n",
        "import sys \n",
        "sys.path.append('deep-learning-from-scratch-2')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'deep-learning-from-scratch-2' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uL3zfaQAA7H",
        "colab_type": "text"
      },
      "source": [
        "# 7章 RNNによる文章生成\n",
        "\n",
        "6章で実装した言語モデルが出力する確率分布に従って単語をサンプリングし，文章を生成する．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7awCMjkQ1oo",
        "colab_type": "text"
      },
      "source": [
        "## 7.1 言語モデルを使った文章生成（`RnnlmGen`，`BetterRnnlmGen`クラス）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAJeMVW6Fiya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from common.functions import softmax\n",
        "from ch06.rnnlm import Rnnlm\n",
        "from ch06.better_rnnlm import BetterRnnlm\n",
        "\n",
        "class RnnlmGen(Rnnlm):\n",
        "  def generate(self, start_id, skip_ids=None, sample_size=100): \n",
        "    '''\n",
        "    start_id: 開始単語のID\n",
        "    skip_ids: <unk>など生成に使いたくない単語のリスト\n",
        "    sample_size=文長\n",
        "    '''\n",
        "    word_ids = [start_id]\n",
        "\n",
        "    x = start_id\n",
        "    while len(word_ids) < sample_size:\n",
        "      x = np.array(x).reshape(1, 1)\n",
        "      score = self.predict(x)  # Softmaxレイヤの直前の出力\n",
        "      p = softmax(score.flatten())  # flatten(): ndarrayを一次元の配列化する\n",
        "\n",
        "      sampled = np.random.choice(len(p), size=1, p=p)  # サンプリング．len(p)は生成されるサンプルの値域最大値，sizeは生成されるサンプル数，pはサンプルする際に使われる確率分布\n",
        "\n",
        "      if (skip_ids is None) or (sampled not in skip_ids):\n",
        "        x = sampled\n",
        "        word_ids.append(int(x))\n",
        "\n",
        "    return word_ids"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYlxeKMkzAkL",
        "colab_type": "text"
      },
      "source": [
        "PTBデータセットで学習した普通のLSTMモデルを利用して文章生成．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSGfdEN4Lzmg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "2b70d851-0c06-443a-9221-bf54ebece401"
      },
      "source": [
        "from dataset import ptb\n",
        "\n",
        "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
        "vocab_size = len(word_to_id)\n",
        "corpus_size = len(corpus)\n",
        "\n",
        "model = RnnlmGen()\n",
        "model.load_params('deep-learning-from-scratch-2/ch06/Rnnlm.pkl')\n",
        "\n",
        "# start文字とskip文字の設定\n",
        "start_word = 'you'\n",
        "start_id = word_to_id[start_word]\n",
        "skip_words = ['N', '<unk>', '$']\n",
        "skip_ids = [word_to_id[w] for w in skip_words]\n",
        "\n",
        "# 文章生成\n",
        "word_ids = model.generate(start_id, skip_ids)\n",
        "txt = ' '.join([id_to_word[i] for i in word_ids])\n",
        "txt = txt.replace(' <eos>', '.\\n')\n",
        "print(txt)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "you mean which was in an official choice.\n",
            " sight relief can rise around in the year.\n",
            " other players could suppliers some other of the film drawn and can decide why the country had n't bolster the going have been grabbed good worse.\n",
            " for the first moment hepatitis a leadership and long president should raise questions close to areas nuclear radio while give both the coleman and a small sudden called him.\n",
            " china 's nations operating for the industry might also reduce law available and considers significant debt owned technologies which can home the economy.\n",
            " that\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AfIQxRf5_To",
        "colab_type": "text"
      },
      "source": [
        "LSTMレイヤを2層にして，各層にDropoutを入れ，さらにEmbeddingの転置行列（H x V, Hは入力単語を表現する隠れベクトルのサイズ，Vは元の語彙数）をAffine Layerの重みにそのまま使うモデル（`ch06/better_rnnlm.py`）に変更すると，生成される文章の質が上がる．\n",
        "（より言語のルールを守った文章になる）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7T-EwmDyz1G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "6e949e65-5f92-4bfa-9c96-413c7f271a71"
      },
      "source": [
        "!curl -o deep-learning-from-scratch-2/ch06/BetterRnnlm.pkl https://www.oreilly.co.jp/pub/9784873118369/BetterRnnlm.pkl"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 37.7M  100 37.7M    0     0  11.1M      0  0:00:03  0:00:03 --:--:-- 11.1M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VzlqYdky1Hf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "f6d9f48d-71d6-48ad-c3cb-2e7c880387d1"
      },
      "source": [
        "from ch06.better_rnnlm import BetterRnnlm  # LSTMレイヤを2層利用して、各層でDropoutするモデル\n",
        "from ch07.rnnlm_gen import BetterRnnlmGen  # RnnlmGenの継承クラスをRnnlmからBetterRnnlmに変更しただけのクラス\n",
        "\n",
        "model = BetterRnnlmGen()\n",
        "model.load_params('deep-learning-from-scratch-2/ch06/BetterRnnlm.pkl')\n",
        "\n",
        "# start文字とskip文字の設定\n",
        "start_word = 'you'\n",
        "start_id = word_to_id[start_word]\n",
        "skip_words = ['N', '<unk>', '$']\n",
        "skip_ids = [word_to_id[w] for w in skip_words]\n",
        "\n",
        "# 文章生成\n",
        "word_ids = model.generate(start_id, skip_ids)\n",
        "txt = ' '.join([id_to_word[i] for i in word_ids])\n",
        "txt = txt.replace(' <eos>', '.\\n')\n",
        "print(txt)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "you supposedly reflect the ability of the new york stock exchange of manhattan.\n",
            " the mega-issues in a company that provides data any embarrassing priority which is n't have one major debt the week does n't be proven during the past two sessions.\n",
            " it did n't cover the letters of a long-term investment sales.\n",
            " in other financial markets markets.\n",
            " stock futures ended slightly higher in thin trading because the stock-market rise price is only handful ahead.\n",
            " stock prices closed lower in thin trading.\n",
            " the board cited one of the market 's recent sell-off in gold\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}